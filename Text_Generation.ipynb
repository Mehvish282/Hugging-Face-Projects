{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoxmJDs73MwSIbsbN8ucQF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TEXT GENERATION"
      ],
      "metadata": {
        "id": "-gyH3z5bUdKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1: Install Transformers Library**\n",
        "\n",
        "Installs the Hugging Face transformers library, which provides pre-trained models for a variety of natural language processing (NLP) tasks including text generation."
      ],
      "metadata": {
        "id": "73bQ1D8hUS1d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PSm9OTXoId64",
        "outputId": "a514cba9-6e87-4883-c6a1-acadfaa16033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2:  Import Required Libraries**\n",
        "\n",
        "\n",
        "Imports essential Python libraries such as pandas, numpy, torch, matplotlib, and seaborn, along with Hugging Face's pipeline for text generation."
      ],
      "metadata": {
        "id": "htNRu7hvUoyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "wx9rxBreI7q9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3: Load Dataset**\n",
        "\n",
        "Loads a CSV file containing poems/texts into a pandas DataFrame. This dataset is used as the input for text generation experiments."
      ],
      "metadata": {
        "id": "14WI4EV5UvNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poems = pd.read_csv('/content/robert_frost_collection.csv')\n",
        "poems.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XYkVtaJcJSo2",
        "outputId": "3cf5358e-ce90-4c03-e67d-a62bfbed1740"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Name   \\\n",
              "0                                         NaN   \n",
              "1        Stopping by Woods on a Snowy Evening   \n",
              "2                                Fire and Ice   \n",
              "3                            The Aim was Song   \n",
              "4  The Need of Being Versed in Country Things   \n",
              "\n",
              "                                             Content     Collection  \\\n",
              "0                                                NaN            NaN   \n",
              "1  Whose woods these are I think I know.   \\nHis ...  New Hampshire   \n",
              "2  Some say the world will end in fire,\\nSome say...  New Hampshire   \n",
              "3  Before man came to blow it right\\nThe wind onc...  New Hampshire   \n",
              "4  The house had gone to bring again\\nTo the midn...  New Hampshire   \n",
              "\n",
              "   Year of Publication  \n",
              "0                  NaN  \n",
              "1               1923.0  \n",
              "2               1923.0  \n",
              "3               1923.0  \n",
              "4               1923.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1badc407-75ad-44eb-837c-ed5ca0a526f7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Content</th>\n",
              "      <th>Collection</th>\n",
              "      <th>Year of Publication</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stopping by Woods on a Snowy Evening</td>\n",
              "      <td>Whose woods these are I think I know.   \\nHis ...</td>\n",
              "      <td>New Hampshire</td>\n",
              "      <td>1923.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Fire and Ice</td>\n",
              "      <td>Some say the world will end in fire,\\nSome say...</td>\n",
              "      <td>New Hampshire</td>\n",
              "      <td>1923.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Aim was Song</td>\n",
              "      <td>Before man came to blow it right\\nThe wind onc...</td>\n",
              "      <td>New Hampshire</td>\n",
              "      <td>1923.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Need of Being Versed in Country Things</td>\n",
              "      <td>The house had gone to bring again\\nTo the midn...</td>\n",
              "      <td>New Hampshire</td>\n",
              "      <td>1923.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1badc407-75ad-44eb-837c-ed5ca0a526f7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1badc407-75ad-44eb-837c-ed5ca0a526f7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1badc407-75ad-44eb-837c-ed5ca0a526f7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b60dfb79-b860-42f8-b385-9cbfadd5f6ee\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b60dfb79-b860-42f8-b385-9cbfadd5f6ee')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b60dfb79-b860-42f8-b385-9cbfadd5f6ee button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "poems",
              "summary": "{\n  \"name\": \"poems\",\n  \"rows\": 109,\n  \"fields\": [\n    {\n      \"column\": \"Name \",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Dust of Snow\",\n          \"The Road not taken\",\n          \"I Will Sing You One O\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"The way a crow\\nShook down on me\\nThe dust of snow\\nFrom a hemlock tree\\nHas given my heart\\nA change of mood\\nAnd saved some part \\nOf a day I had rued.\",\n          \"Two roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nAnd both that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I kept the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I\\nI took the one less traveled by,\\nAnd that has made all the difference.\\n\",\n          \"It was long I lay\\nAwake that night\\nWishing the tower\\nWould name the hour\\nAnd tell me whether\\nTo call it day\\nThough not yet light\\nAnd give up sleep.\\nThe snow fell deep\\nWith the hiss of spray;\\nTwo winds would meet,\\nOne down one street,\\nOne down another,\\nAnd fight in a smother\\nOf dust and feather.\\nI could not say,\\nBut feared the cold\\nHad checked the pace\\nOf the tower clock\\nBy tying together\\nIts hands of gold\\nBefore its face.\\nThen came one knock!\\nA note unruffled\\nOf earthly weather,\\nThough strange and muffled.\\nThe tower said, One!\\nAnd then a steeple.\\nThey spoke to themselves\\nAnd such few people\\nAs winds might rouse\\nFrom sleeping warm\\nBut not unhouse.\\nThey left the storm\\nThat struck en masse\\nMy window glass\\nLike a beaded fur.\\nIn that grave One\\nThey spoke of the sun\\nAnd moon and stars,\\nSaturn and Mars\\nAnd Jupiter.\\nStill more unfettered,\\nThey left the named\\nAnd spoke of the lettered,\\nThe sigmas and taus\\nOf constellations.\\nThey filled their throats\\nWith the furthest bodies\\nTo which man sends his\\nSpeculation,\\nBeyond which God is;\\nThe cosmic motes\\nOf yawning lenses.\\nTheir solemn peals\\nWere not their own:\\nThey spoke for the clock\\nWith whose vast wheels\\nTheirs interlock.\\nIn that grave word\\nUttered alone\\nThe utmost star\\nTrembled and stirred,\\nThough set so far\\nIts whirling frenzies\\nAppear like standing\\nIn one self station.\\nIt has not ranged,\\nAnd save for the wonder\\nOf once expanding\\nTo be a nova,\\nIt has not changed\\nTo the eye of man\\nOn planets over\\nAround and under\\nIt in creation\\nSince man began\\nTo drag down man\\nAnd nation nation.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Collection\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Mountain Interval\",\n          \"West-Running Book\",\n          \"A Witness tree\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year of Publication\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2347.073156404908,\n        \"min\": 1913.0,\n        \"max\": 19166.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1928.0,\n          1942.0,\n          1923.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4: Clean and Preprocess Poem Lines**\n",
        "\n",
        "Cleans the text data by splitting poems into individual lines and filtering out empty lines. Prepares the content for line-by-line text generation."
      ],
      "metadata": {
        "id": "DBQR5IE-VA0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content = poems['Content'].dropna().tolist()"
      ],
      "metadata": {
        "id": "--h2PChWJhtw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = []\n",
        "for poem in content:\n",
        " for line in poem.split(\"\\n\"):\n",
        "  lines.append(line.rstrip())"
      ],
      "metadata": {
        "id": "pU67uzlEJ3au"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = [line for line in lines if len(line) >0]\n",
        "lines[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ramtKxKnjg",
        "outputId": "809f7fd6-c011-49fb-dea1-a87607bd9d9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Whose woods these are I think I know.',\n",
              " 'His house is in the village though;',\n",
              " 'He will not see me stopping here',\n",
              " 'To watch his woods fill up with snow.',\n",
              " 'My little horse must think it queer']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5: Initialize Text Generation Pipeline**\n",
        "\n",
        "Initializes the Hugging Face text generation pipeline using a default model (e.g., GPT-2). This model will be used to generate new text based on the input lines."
      ],
      "metadata": {
        "id": "lWxu0v8oVJG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen = pipeline('text-generation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imHydFzEK-jA",
        "outputId": "55b51053-50b7-4edc-cdbc-b05ceb48feb2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bSi6MDYnLMPO",
        "outputId": "b3e17bba-7b2f-4abc-f44d-dc721f200cd4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Whose woods these are I think I know.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6: Generate Text for Sample Lines**\n",
        "\n",
        "Uses the pipeline to generate short text continuations (with max_length=20) for the first two lines of the dataset. Demonstrates basic functionality."
      ],
      "metadata": {
        "id": "T2zdwoq4VVSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen(lines[0], max_length = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DgwJRexLRIQ",
        "outputId": "e29cee22-447f-4bcd-8f56-1368caaa3b3f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Whose woods these are I think I know. I don\\'t know if I\\'ve ever heard of one of them. I guess maybe it\\'s just the shape of the trees. I guess I\\'ve just got to get my hands on one or two of them. I mean, there\\'s this one. It\\'s a little long. I think I\\'ve got it on, I guess. I guess the name\\'s just, like, \"Budman.\" I think it\\'s a little long. I mean, I\\'ve never seen it that long. I think it\\'s a little too long. It\\'s like a big, white thing. Like, the one in the upper left. I know the name\\'s a little bit long on the back, I know the name\\'s a little bit long on the front. I know it\\'s a little bit long. \"Budman\" is just like, \"Budman.\" It\\'s like, \"Budman!\" But I don\\'t know how long it\\'s been, I just don\\'t think it\\'s been long enough to go to the store. I have a good idea what that is. I\\'ve never seen it that long, but I\\'m just like, \"Budman.\" So when I see it, I just like it. I don\\'t know'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen(lines[1], max_length = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJyhxMEXNFIE",
        "outputId": "3b5f2429-ec75-410c-cdf3-351bd5ba6427"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'His house is in the village though; and there is a place for the people to go to, where the people can have a meal, and drink and eat.\\n\\n22 And they came to the house of the sons of Gai, and they were going to the village, and there was Gai there, and the sons of Gai went unto them and smote them, and they said to Gai, \"Why do you say that he does not bring food for us?\" And Gai answered, \"I will bring food from him, and we will not be hungry.\" And Gai said, \"I will not give you food of any kind to eat, for I am not a man of any gods, and I do not know who or what you are, but I have heard that the son of Gai was able to accomplish some great thing.\" And Gai went to his wife and said to her, \"I have heard that the son of Gai lived for a long time and suffered for his people, and he was able to accomplish some great thing; and when he was able to accomplish some great thing he did not eat, and went to another man, and there he came to the village, and he said unto Gai, \"Why do you say that he did not'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7: Generate and Display Wrapped Output**\n",
        "\n",
        "Defines a helper function using Pythonâ€™s textwrap module and generates a longer text continuation (with max_length=30) for the first poem line and prints it using the wrapping function for better formatting."
      ],
      "metadata": {
        "id": "TQsdTFgfVeZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "def wrap(x):\n",
        "  return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings= True)"
      ],
      "metadata": {
        "id": "78PX5fezM5dt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = gen(lines[0], max_length = 30)\n",
        "print (wrap (out[0]['generated_text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiOwmkBhNYHh",
        "outputId": "87f22575-0942-402f-eb72-923d16e834f2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whose woods these are I think I know.  And he would like to see them,\n",
            "and see where he goes, and see what he comes back with.  And he has a\n",
            "lot of problems with the people he's supposed to help, and he's not\n",
            "the guy that's supposed to lead you to the end.  But it's also a real\n",
            "problem for me.  I know how to do all of this, and I've been doing it\n",
            "all my life, but I have so many problems with people, and I've been\n",
            "doing it all my life, and I've been doing it all my life with a lot of\n",
            "different people.  And so I just want to get those problems to a point\n",
            "where I can actually get out, and to put a stop to them.  It's like\n",
            "I'm the one that's going to do it, and I'm going to do it all at once;\n",
            "I'm going to do it all at once.\n",
            "\n",
            "\n",
            "I don't have to ask about\n",
            "everything, it's just, and it's going to be a very, very hard job for\n",
            "me to do it all at once.  I just like to do it all at once, and I know\n",
            "that I don't have to ask about everything.  So I do all of this\n",
            "through work, through all of this, and I just\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8: Custom Prompt Text Generation**\n",
        "\n",
        "Demonstrates text generation using a custom prompt. Generates a longer continuation (up to 100 tokens) to show how the model handles novel inputs."
      ],
      "metadata": {
        "id": "akBS_mBWV1rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"transformers have a wide variet of applications in nlp\"\n",
        "out= gen(prompt, max_length = 100)\n",
        "print(wrap(out[0]['generated_text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBayQ1eqN1EE",
        "outputId": "6eac3236-5e46-4ac8-9e90-8a1f50dd09d7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers have a wide variet of applications in nlp.  In this post,\n",
            "we'll look at two popular implementations of the NLP library:\n",
            "\n",
            "The\n",
            "first implementation of the NLP library uses a standard library called\n",
            "the NLP_NPPARSE. This is used by a number of popular programs such as\n",
            "the NLP_NPPARSE and NLP_NPPARSE. The second implementation uses a\n",
            "standard library called the NLP_NPPARSE_ENV. The NLP_NPPARSE_ENV is a\n",
            "wrapper around the NLP_NPPARSE, which implements functions that return\n",
            "different values for different input values.  In this post, we will\n",
            "assume that the NLP_NPPARSE_ENV is the same as the\n",
            "NLP_NPPARSE_CURRENT_HANDLER.\n",
            "\n",
            "The following code snippet shows how to\n",
            "use the NLP library to build a new string that is converted to a\n",
            "string of integer characters.\n",
            "\n",
            "// create string from string var string\n",
            "= 'abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz' // convert\n",
            "string to string var string = [ 'abcdefghijklmnopqrstuvw\n"
          ]
        }
      ]
    }
  ]
}